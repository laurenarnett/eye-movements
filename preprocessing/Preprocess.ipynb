{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fixmat as ft\n",
    "from scipy.ndimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = '/Users/Lauren/cahv/data/etdb.hdf5'\n",
    "#f = h5py.File(filename, 'r')\n",
    "#baseline,meta = ft.load('/Users/Lauren/cahv/data/etdb.hdf5', 'Baseline')\n",
    "#appc,meta_appc = ft.load('/Users/Lauren/cahv/data/APP_raw.hdf', \"APP\")\n",
    "eeg,meta_eeg = ft.load('/Users/Lauren/eye-movements/data/hdf/EEG_raw.hdf', \"EEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for Folder 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing fixation locations by drawing circles on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = range(1, len(os.listdir(\"/Users/Lauren/eye-movements/data/14/\"))+1)\n",
    "\n",
    "for i in img_idx:\n",
    "    test_img_data = eeg.groupby(\"filenumber\").get_group(i)\n",
    "    img = cv2.imread(\"/Users/Lauren/eye-movements/data/14/\" + str(i) + \".jpg\")\n",
    "    for idx,row in test_img_data.iterrows():\n",
    "        print(int(row[\"x\"]))\n",
    "        print(int(row[\"y\"]))\n",
    "        cv2.circle(img, (int(row[\"x\"]),int(row[\"y\"])),7,color=(0,255,0))\n",
    "        \n",
    "    cv2.imwrite(\"/Users/Lauren/eye-movements/data/viz/14/\" + str(i) + \".jpg\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the ground-truth mapping for fixation locations using a Gaussian filter:\n",
    "\n",
    "1) add values to pixel of fixation location and surrounding pixels to account for angle of error in fixation tracking\n",
    "\n",
    "2) Gaussian filter applied to fixation locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-d5b974923998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/Lauren/eye-movements/data/14/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtest_img_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filenumber\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtest_img_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_img_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_img_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mimg_filter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "img_idx = range(1, len(os.listdir(\"/Users/Lauren/eye-movements/data/14/\"))+1)\n",
    "\n",
    "for i in img_idx:\n",
    "\n",
    "    \n",
    "    img = cv2.imread(\"/Users/Lauren/eye-movements/data/14/\" + str(i) + \".jpg\")\n",
    "    img_filter = np.zeros((img.shape[0],img.shape[1]))\n",
    "    test_img_data = eeg.groupby(\"filenumber\").get_group(i)\n",
    "    test_img_data = test_img_data[test_img_data.y < img_filter.shape[0]]\n",
    "    test_img_data = test_img_data[test_img_data.x < img_filter.shape[1]]\n",
    "    test_img_data = test_img_data[test_img_data.x >= 0]\n",
    "    test_img_data = test_img_data[test_img_data.y >= 0]\n",
    "    \n",
    "    m = range(img.shape[0])\n",
    "    n = range(img.shape[1])\n",
    "    for idx,row in test_img_data.iterrows():\n",
    "        \n",
    "        # add values to surrounding pixels according to gaussian\n",
    "        y = int(row[\"x\"])\n",
    "        x = int(row[\"y\"])\n",
    "        img_filter[x,y] += 4\n",
    "        top = x - 1\n",
    "        bottom = x + 1\n",
    "        left = y - 1\n",
    "        right = y + 1\n",
    "        if top in m:\n",
    "            img_filter[top,y] += 2\n",
    "            if left in n:\n",
    "                img_filter[top,left] += 1\n",
    "            if right in n:\n",
    "                img_filter[top,right] += 1\n",
    "        if bottom in m:\n",
    "            img_filter[bottom,y] += 2\n",
    "            if left in n:\n",
    "                img_filter[bottom,left] += 1\n",
    "            if right in n:\n",
    "                img_filter[bottom,right] += 1\n",
    "        if left in n:\n",
    "            img_filter[x,left] += 2\n",
    "        if right in n:\n",
    "            img_filter[x,right] += 2\n",
    "        \n",
    "        \n",
    "    blurred = gaussian_filter(img_filter, sigma=5)\n",
    "    \n",
    "    # normalize\n",
    "    blurred *= (255/np.amax(blurred))\n",
    "    cv2.imwrite(\"/Users/Lauren/eye-movements/data/filters/14/\" + str(i) + \".jpg\", blurred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
